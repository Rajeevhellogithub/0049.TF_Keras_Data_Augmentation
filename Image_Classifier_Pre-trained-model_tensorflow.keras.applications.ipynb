{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69ce33e2-1e1d-4272-a5d6-49a902d8d55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from keras.utils import array_to_img ,img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a2d9fda-5a21-472c-91b0-66db245a2650",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2, preprocess_input, decode_predictions\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n",
    "from tensorflow.keras.applications.vgg19 import VGG19, preprocess_input, decode_predictions\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.applications.xception import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.applications.densenet import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.applications import NASNetMobile\n",
    "from tensorflow.keras.applications.nasnet import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.applications import NASNetLarge\n",
    "from tensorflow.keras.applications.nasnet import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.applications import EfficientNetV2B0\n",
    "from tensorflow.keras.applications.efficientnet_v2 import preprocess_input, decode_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae12966e-c3bc-4966-b2ea-7c02ec515884",
   "metadata": {},
   "source": [
    "* Demonstrates how to use a pre-trained ResNet50 model to classify an image.\n",
    "-------------------------------------------------------\n",
    "* Import necessary libraries:\n",
    "\n",
    "  * numpy for numerical operations.\n",
    "  * time for measuring inference time.\n",
    "  * keras for accessing the Keras API.\n",
    "  * ImageDataGenerator for image data augmentation.\n",
    "  * load_img, img_to_array, array_to_img for image loading and manipulation.\n",
    "  * ResNet50, preprocess_input, decode_predictions for loading and using the pre-trained ResNet50 model.\n",
    "-------------------------------------------------------\n",
    "* Load and preprocess the image:\n",
    "\n",
    "  * img_path: Specifies the path to the image file.\n",
    "  * load_img(): Loads the image from the specified path.\n",
    "  * img_to_array(): Converts the loaded image into a NumPy array.\n",
    "  * np.expand_dims(img_array, axis=0): Adds a batch dimension to the array, as the model expects a batch of images as input.\n",
    "  * preprocess_input(img_array): Preprocesses the image array according to the requirements of the ResNet50 model (e.g., normalization, rescaling).\n",
    "-------------------------------------------------------\n",
    "* Load the pre-trained ResNet50 model:\n",
    "\n",
    "    * model = ResNet50(weights='imagenet'): Loads the pre-trained ResNet50 model with weights trained on the ImageNet dataset.\n",
    "-------------------------------------------------------\n",
    "* Make predictions:\n",
    "\n",
    "    * start_time = time.time(): Starts a timer to measure inference time.\n",
    "    * predictions = model.predict(img_array): Uses the loaded model to make predictions on the preprocessed image.\n",
    "    * end_time = time.time(): Ends the timer.\n",
    "-------------------------------------------------------\n",
    "* Decode and print predictions:\n",
    "\n",
    "    * decoded_predictions = decode_predictions(predictions, top=5): Decodes the model's output into human-readable labels and probabilities.\n",
    "    * Prints the top 5 predicted classes and their probabilities.\n",
    "-------------------------------------------------------\n",
    "* Print model information:\n",
    "\n",
    "    * top_class_index = np.argmax(predictions[0]): Finds the index of the top predicted class.\n",
    "    * inference_time_ms: Calculates and prints the inference time in milliseconds.\n",
    "    * model_size_MB: Calculates and prints the size of the model in megabytes.\n",
    "    * num_parameters: Prints the total number of parameters in the model.\n",
    "    * model_depth: Prints the number of layers in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73de0954-3a3a-44c9-b2e2-8e15c690ac14",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(weights='imagenet')\n",
    "img_path = r'E:\\PYTHONCLASSTF\\PrakashSenapati\\2024_11_25_Data_Augmentation_Kera_Packages\\dog_chihuahua.jpeg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = preprocess_input(img_array)\n",
    "\n",
    "start_time = time.time()\n",
    "predictions = model.predict(img_array)\n",
    "end_time = time.time()\n",
    "\n",
    "decoded_predictions = decode_predictions(predictions, top=5)[0]\n",
    "print('Predictions:')\n",
    "\n",
    "for i, (imagenet_id, label, score) in enumerate(decoded_predictions):\n",
    "    print(f'{i + 1}: {label} ({score:.2f})')\n",
    "\n",
    "top_class_index = np.argmax(predictions[0])\n",
    "print(f'\\nTop Prediction Class Index: {top_class_index}')\n",
    "\n",
    "inference_time_ms = (end_time - start_time) * 1000.0\n",
    "print(f\"Inference Time: {inference_time_ms:.2f} ms\")\n",
    "\n",
    "model_size_MB = model.count_params() * 4 / (1024 ** 2)\n",
    "print(f\"Size (MB): {model_size_MB:.2f} MB\")\n",
    "\n",
    "num_parameters = model.count_params()\n",
    "model_depth = len(model.layers)\n",
    "\n",
    "print(f\"Parameters: {num_parameters}\")\n",
    "print(f\"Depth: {model_depth}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc7e294-80e8-46ff-9487-90a5e3330131",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(weights='imagenet')\n",
    "img_path = r'E:\\PYTHONCLASSTF\\PrakashSenapati\\2024_11_25_Data_Augmentation_Kera_Packages\\tharjeep.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = preprocess_input(img_array)\n",
    "predictions = model.predict(img_array)\n",
    "decoded_predictions = decode_predictions(predictions, top=3)[0]\n",
    "print('Predictions:')\n",
    "\n",
    "for i, (imagenet_id, label, score) in enumerate(decoded_predictions):\n",
    "    print(f'{i + 1}: {label} ({score:.2f})')\n",
    "\n",
    "top_class_index = np.argmax(predictions[0])\n",
    "print(f'\\nTop Prediction Class Index: {top_class_index}')\n",
    "\n",
    "# Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
    "  # 4218880/102967424 ━━━━━━━━━━━━━━━━━━━━ 1:52 1us/step\n",
    "# 98.2 MB Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ca93c36-7946-4b9e-b7b7-efc27ba53db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.utils import image_dataset_from_directory\n",
    "# from keras.utils import array_to_img ,img_to_array, load_img\n",
    "\n",
    "# datagen = ImageDataGenerator(\n",
    "# rotation_range=40,\n",
    "# width_shift_range=0.2,\n",
    "# height_shift_range=0.2,\n",
    "# shear_range=0.2,\n",
    "# zoom_range=0.2,\n",
    "# horizontal_flip=True,\n",
    "# fill_mode='nearest')\n",
    "\n",
    "# img = load_img(r'E:\\PYTHONCLASSTF\\PrakashSenapati\\2024_11_25_Data_Augmentation_Kera_Packages\\tharjeep.jpg')\n",
    "\n",
    "# x = img_to_array(img)\n",
    "# x = x.reshape((1,) + x.shape)\n",
    "\n",
    "# sav_dir = r'E:\\PYTHONCLASSTF\\PrakashSenapati\\2024_11_25_Data_Augmentation_Kera_Packages\\Thar'\n",
    "\n",
    "# i=0\n",
    "# for batch in datagen.flow(x, batch_size=1, save_to_dir=sav_dir, save_prefix='thar', save_format='jpg'):\n",
    "#     i += 1\n",
    "#     if i > 29:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac63a9fe-a4a5-4fe0-b639-c3912536dbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras.applications.ResNet50(\n",
    "# include_top=True,\n",
    "# weights='imagenet',\n",
    "# input_tensor=None,\n",
    "# input_shape=None,\n",
    "# pooling=None,\n",
    "# classes=1000,\n",
    "# classifier_activation='softmax',\n",
    "# )\n",
    "\n",
    "# Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
    "#  15581184/102967424 ━━━━━━━━━━━━━━━━━━━━ 4:36 3us/step\n",
    "# 98.2 MB Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb0968e-0957-44b5-9c74-13743efc5077",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50V2(weights='imagenet')\n",
    "img_path = r'E:\\PYTHONCLASSTF\\PrakashSenapati\\2024_11_25_Data_Augmentation_Kera_Packages\\tharjeep.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = preprocess_input(img_array)\n",
    "predictions = model.predict(img_array)\n",
    "decoded_predictions = decode_predictions(predictions, top=3)[0]\n",
    "print('Predictions:')\n",
    "\n",
    "for i, (imagenet_id, label, score) in enumerate(decoded_predictions):\n",
    "    print(f'{i + 1}: {label} ({score:.2f})')\n",
    "\n",
    "top_class_index = np.argmax(predictions[0])\n",
    "print(f'\\nTop Prediction Class Index: {top_class_index}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5857d057-2d71-4205-8a44-be2976ba72e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16(weights='imagenet')\n",
    "img_path = r'E:\\PYTHONCLASSTF\\PrakashSenapati\\2024_11_25_Data_Augmentation_Kera_Packages\\tharjeep.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = preprocess_input(img_array)\n",
    "predictions = model.predict(img_array)\n",
    "decoded_predictions = decode_predictions(predictions, top=3)[0]\n",
    "print('Predictions:')\n",
    "\n",
    "for i, (imagenet_id, label, score) in enumerate(decoded_predictions):\n",
    "    print(f'{i + 1}: {label} ({score:.2f})')\n",
    "\n",
    "top_class_index = np.argmax(predictions[0])\n",
    "print(f'\\nTop Prediction Class Index: {top_class_index}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef1048f-8bea-4bd1-aef4-e69a333ff487",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16(weights='imagenet')\n",
    "img_path = r'E:\\PYTHONCLASSTF\\PrakashSenapati\\2024_11_25_Data_Augmentation_Kera_Packages\\peacock.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = preprocess_input(img_array)\n",
    "predictions = model.predict(img_array)\n",
    "decoded_predictions = decode_predictions(predictions, top=3)[0]\n",
    "print('Predictions:')\n",
    "\n",
    "for i, (imagenet_id, label, score) in enumerate(decoded_predictions):\n",
    "    print(f'{i + 1}: {label} ({score:.2f})')\n",
    "\n",
    "top_class_index = np.argmax(predictions[0])\n",
    "print(f'\\nTop Prediction Class Index: {top_class_index}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabe66d6-0e89-4c41-ba70-fe8396140f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG19(weights='imagenet')\n",
    "img_path = r'E:\\PYTHONCLASSTF\\PrakashSenapati\\2024_11_25_Data_Augmentation_Kera_Packages\\dog_chihuahua.jpeg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = preprocess_input(img_array)\n",
    "predictions = model.predict(img_array)\n",
    "decoded_predictions = decode_predictions(predictions, top=3)[0]\n",
    "print('Predictions:')\n",
    "\n",
    "for i, (imagenet_id, label, score) in enumerate(decoded_predictions):\n",
    "    print(f'{i + 1}: {label} ({score:.2f})')\n",
    "\n",
    "top_class_index = np.argmax(predictions[0])\n",
    "print(f'\\nTop Prediction Class Index: {top_class_index}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735bbf27-29cf-4628-a1e5-530edb273b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG19(weights='imagenet')\n",
    "img_path = r'E:\\PYTHONCLASSTF\\PrakashSenapati\\2024_11_25_Data_Augmentation_Kera_Packages\\dog_chihuahua.jpeg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = preprocess_input(img_array)\n",
    "predictions = model.predict(img_array)\n",
    "decoded_predictions = decode_predictions(predictions, top=8)[0]\n",
    "print('Predictions:')\n",
    "\n",
    "for i, (imagenet_id, label, score) in enumerate(decoded_predictions):\n",
    "    print(f'{i + 1}: {label} ({score:.2f})')\n",
    "\n",
    "top_class_index = np.argmax(predictions[0])\n",
    "print(f'\\nTop Prediction Class Index: {top_class_index}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27e4901-3572-4616-aa93-64a4d56a9efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50V2(weights='imagenet')\n",
    "img_path = r'E:\\PYTHONCLASSTF\\PrakashSenapati\\2024_11_25_Data_Augmentation_Kera_Packages\\dog_chihuahua.jpeg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = preprocess_input(img_array)\n",
    "predictions = model.predict(img_array)\n",
    "decoded_predictions = decode_predictions(predictions, top=10)[0]\n",
    "print('Predictions:')\n",
    "\n",
    "for i, (imagenet_id, label, score) in enumerate(decoded_predictions):\n",
    "    print(f'{i + 1}: {label} ({score:.2f})')\n",
    "\n",
    "top_class_index = np.argmax(predictions[0])\n",
    "print(f'\\nTop Prediction Class Index: {top_class_index}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c901ad-4797-4f91-9c75-9b8711a6157d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50V2(weights='imagenet')\n",
    "img_path = r'E:\\PYTHONCLASSTF\\PrakashSenapati\\2024_11_25_Data_Augmentation_Kera_Packages\\dog_chihuahua.jpeg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = preprocess_input(img_array)\n",
    "\n",
    "start_time = time.time()\n",
    "predictions = model.predict(img_array)\n",
    "end_time = time.time()\n",
    "\n",
    "decoded_predictions = decode_predictions(predictions, top=5)[0]\n",
    "print('Predictions:')\n",
    "\n",
    "for i, (imagenet_id, label, score) in enumerate(decoded_predictions):\n",
    "    print(f'{i + 1}: {label} ({score:.2f})')\n",
    "\n",
    "top_class_index = np.argmax(predictions[0])\n",
    "print(f'\\nTop Prediction Class Index: {top_class_index}')\n",
    "\n",
    "inference_time_ms = (end_time - start_time) * 1000.0\n",
    "print(f\"Inference Time: {inference_time_ms:.2f} ms\")\n",
    "\n",
    "model_size_MB = model.count_params() * 4 / (1024 ** 2)\n",
    "print(f\"Size (MB): {model_size_MB:.2f} MB\")\n",
    "\n",
    "num_parameters = model.count_params()\n",
    "model_depth = len(model.layers)\n",
    "\n",
    "print(f\"Parameters: {num_parameters}\")\n",
    "print(f\"Depth: {model_depth}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a1b0c8-d13f-47b2-bcdb-7d0192cba112",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG19(weights='imagenet')\n",
    "img_path = r'E:\\PYTHONCLASSTF\\PrakashSenapati\\2024_11_25_Data_Augmentation_Kera_Packages\\dog_chihuahua.jpeg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = preprocess_input(img_array)\n",
    "\n",
    "start_time = time.time()\n",
    "predictions = model.predict(img_array)\n",
    "end_time = time.time()\n",
    "\n",
    "decoded_predictions = decode_predictions(predictions, top=5)[0]\n",
    "print('Predictions:')\n",
    "\n",
    "for i, (imagenet_id, label, score) in enumerate(decoded_predictions):\n",
    "    print(f'{i + 1}: {label} ({score:.2f})')\n",
    "\n",
    "top_class_index = np.argmax(predictions[0])\n",
    "print(f'\\nTop Prediction Class Index: {top_class_index}')\n",
    "\n",
    "inference_time_ms = (end_time - start_time) * 1000.0\n",
    "print(f\"Inference Time: {inference_time_ms:.2f} ms\")\n",
    "\n",
    "model_size_MB = model.count_params() * 4 / (1024 ** 2)\n",
    "print(f\"Size (MB): {model_size_MB:.2f} MB\")\n",
    "\n",
    "num_parameters = model.count_params()\n",
    "model_depth = len(model.layers)\n",
    "\n",
    "print(f\"Parameters: {num_parameters}\")\n",
    "print(f\"Depth: {model_depth}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e115368b-97bf-4a8a-9be7-96bdc5a283a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16(weights='imagenet')\n",
    "img_path = r'E:\\PYTHONCLASSTF\\PrakashSenapati\\2024_11_25_Data_Augmentation_Kera_Packages\\dog_chihuahua.jpeg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = preprocess_input(img_array)\n",
    "\n",
    "start_time = time.time()\n",
    "predictions = model.predict(img_array)\n",
    "end_time = time.time()\n",
    "\n",
    "decoded_predictions = decode_predictions(predictions, top=5)[0]\n",
    "print('Predictions:')\n",
    "\n",
    "for i, (imagenet_id, label, score) in enumerate(decoded_predictions):\n",
    "    print(f'{i + 1}: {label} ({score:.2f})')\n",
    "\n",
    "top_class_index = np.argmax(predictions[0])\n",
    "print(f'\\nTop Prediction Class Index: {top_class_index}')\n",
    "\n",
    "inference_time_ms = (end_time - start_time) * 1000.0\n",
    "print(f\"Inference Time: {inference_time_ms:.2f} ms\")\n",
    "\n",
    "model_size_MB = model.count_params() * 4 / (1024 ** 2)\n",
    "print(f\"Size (MB): {model_size_MB:.2f} MB\")\n",
    "\n",
    "num_parameters = model.count_params()\n",
    "model_depth = len(model.layers)\n",
    "\n",
    "print(f\"Parameters: {num_parameters}\")\n",
    "print(f\"Depth: {model_depth}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c29b28-8dba-454f-ae83-b5c4aa9949cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Xception(weights='imagenet')\n",
    "img_path = r'E:\\PYTHONCLASSTF\\PrakashSenapati\\2024_11_25_Data_Augmentation_Kera_Packages\\dog_chihuahua.jpeg'\n",
    "img = image.load_img(img_path, target_size=(299, 299))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = preprocess_input(img_array)\n",
    "\n",
    "start_time = time.time()\n",
    "predictions = model.predict(img_array)\n",
    "end_time = time.time()\n",
    "\n",
    "decoded_predictions = decode_predictions(predictions, top=5)[0]\n",
    "print('Predictions:')\n",
    "\n",
    "for i, (imagenet_id, label, score) in enumerate(decoded_predictions):\n",
    "    print(f'{i + 1}: {label} ({score:.2f})')\n",
    "\n",
    "top_class_index = np.argmax(predictions[0])\n",
    "print(f'\\nTop Prediction Class Index: {top_class_index}')\n",
    "\n",
    "inference_time_ms = (end_time - start_time) * 1000.0\n",
    "print(f\"Inference Time: {inference_time_ms:.2f} ms\")\n",
    "\n",
    "model_size_MB = model.count_params() * 4 / (1024 ** 2)\n",
    "print(f\"Size (MB): {model_size_MB:.2f} MB\")\n",
    "\n",
    "num_parameters = model.count_params()\n",
    "model_depth = len(model.layers)\n",
    "\n",
    "print(f\"Parameters: {num_parameters}\")\n",
    "print(f\"Depth: {model_depth}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa5f602-5e3a-458b-9c59-6726a1d423fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InceptionV3(weights='imagenet')\n",
    "img_path = r'E:\\PYTHONCLASSTF\\PrakashSenapati\\2024_11_25_Data_Augmentation_Kera_Packages\\dog_chihuahua.jpeg'\n",
    "img = image.load_img(img_path, target_size=(299, 299))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = preprocess_input(img_array)\n",
    "\n",
    "start_time = time.time()\n",
    "predictions = model.predict(img_array)\n",
    "end_time = time.time()\n",
    "\n",
    "decoded_predictions = decode_predictions(predictions, top=5)[0]\n",
    "print('Predictions:')\n",
    "\n",
    "for i, (imagenet_id, label, score) in enumerate(decoded_predictions):\n",
    "    print(f'{i + 1}: {label} ({score:.2f})')\n",
    "\n",
    "top_class_index = np.argmax(predictions[0])\n",
    "print(f'\\nTop Prediction Class Index: {top_class_index}')\n",
    "\n",
    "inference_time_ms = (end_time - start_time) * 1000.0\n",
    "print(f\"Inference Time: {inference_time_ms:.2f} ms\")\n",
    "\n",
    "model_size_MB = model.count_params() * 4 / (1024 ** 2)\n",
    "print(f\"Size (MB): {model_size_MB:.2f} MB\")\n",
    "\n",
    "num_parameters = model.count_params()\n",
    "model_depth = len(model.layers)\n",
    "\n",
    "print(f\"Parameters: {num_parameters}\")\n",
    "print(f\"Depth: {model_depth}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b6f0a2-5ed1-43b1-8b88-4a2cf8a90b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MobileNetV2(weights='imagenet')\n",
    "img_path = r'E:\\PYTHONCLASSTF\\PrakashSenapati\\2024_11_25_Data_Augmentation_Kera_Packages\\dog_chihuahua.jpeg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = preprocess_input(img_array)\n",
    "\n",
    "start_time = time.time()\n",
    "predictions = model.predict(img_array)\n",
    "end_time = time.time()\n",
    "\n",
    "decoded_predictions = decode_predictions(predictions, top=5)[0]\n",
    "print('Predictions:')\n",
    "\n",
    "for i, (imagenet_id, label, score) in enumerate(decoded_predictions):\n",
    "    print(f'{i + 1}: {label} ({score:.2f})')\n",
    "\n",
    "top_class_index = np.argmax(predictions[0])\n",
    "print(f'\\nTop Prediction Class Index: {top_class_index}')\n",
    "\n",
    "inference_time_ms = (end_time - start_time) * 1000.0\n",
    "print(f\"Inference Time: {inference_time_ms:.2f} ms\")\n",
    "\n",
    "model_size_MB = model.count_params() * 4 / (1024 ** 2)\n",
    "print(f\"Size (MB): {model_size_MB:.2f} MB\")\n",
    "\n",
    "num_parameters = model.count_params()\n",
    "model_depth = len(model.layers)\n",
    "\n",
    "print(f\"Parameters: {num_parameters}\")\n",
    "print(f\"Depth: {model_depth}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7851852-a4e7-4b88-9652-413562f32f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DenseNet121(weights='imagenet')\n",
    "img_path = r'E:\\PYTHONCLASSTF\\PrakashSenapati\\2024_11_25_Data_Augmentation_Kera_Packages\\dog_chihuahua.jpeg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = preprocess_input(img_array)\n",
    "\n",
    "start_time = time.time()\n",
    "predictions = model.predict(img_array)\n",
    "end_time = time.time()\n",
    "\n",
    "decoded_predictions = decode_predictions(predictions, top=5)[0]\n",
    "print('Predictions:')\n",
    "\n",
    "for i, (imagenet_id, label, score) in enumerate(decoded_predictions):\n",
    "    print(f'{i + 1}: {label} ({score:.2f})')\n",
    "\n",
    "top_class_index = np.argmax(predictions[0])\n",
    "print(f'\\nTop Prediction Class Index: {top_class_index}')\n",
    "\n",
    "inference_time_ms = (end_time - start_time) * 1000.0\n",
    "print(f\"Inference Time: {inference_time_ms:.2f} ms\")\n",
    "\n",
    "model_size_MB = model.count_params() * 4 / (1024 ** 2)\n",
    "print(f\"Size (MB): {model_size_MB:.2f} MB\")\n",
    "\n",
    "num_parameters = model.count_params()\n",
    "model_depth = len(model.layers)\n",
    "\n",
    "print(f\"Parameters: {num_parameters}\")\n",
    "print(f\"Depth: {model_depth}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a61904-cfaa-4e5d-b6b8-d6220d2b95ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NASNetMobile(weights='imagenet')\n",
    "img_path = r'E:\\PYTHONCLASSTF\\PrakashSenapati\\2024_11_25_Data_Augmentation_Kera_Packages\\dog_chihuahua.jpeg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = preprocess_input(img_array)\n",
    "\n",
    "start_time = time.time()\n",
    "predictions = model.predict(img_array)\n",
    "end_time = time.time()\n",
    "\n",
    "decoded_predictions = decode_predictions(predictions, top=5)[0]\n",
    "print('Predictions:')\n",
    "\n",
    "for i, (imagenet_id, label, score) in enumerate(decoded_predictions):\n",
    "    print(f'{i + 1}: {label} ({score:.2f})')\n",
    "\n",
    "top_class_index = np.argmax(predictions[0])\n",
    "print(f'\\nTop Prediction Class Index: {top_class_index}')\n",
    "\n",
    "inference_time_ms = (end_time - start_time) * 1000.0\n",
    "print(f\"Inference Time: {inference_time_ms:.2f} ms\")\n",
    "\n",
    "model_size_MB = model.count_params() * 4 / (1024 ** 2)\n",
    "print(f\"Size (MB): {model_size_MB:.2f} MB\")\n",
    "\n",
    "num_parameters = model.count_params()\n",
    "model_depth = len(model.layers)\n",
    "\n",
    "print(f\"Parameters: {num_parameters}\")\n",
    "print(f\"Depth: {model_depth}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2292a72-ed86-446d-a2ec-cf43911175cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NASNetLarge(weights='imagenet')\n",
    "img_path = r'E:\\PYTHONCLASSTF\\PrakashSenapati\\2024_11_25_Data_Augmentation_Kera_Packages\\dog_chihuahua.jpeg'\n",
    "img = image.load_img(img_path, target_size=(331, 331))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = preprocess_input(img_array)\n",
    "\n",
    "start_time = time.time()\n",
    "predictions = model.predict(img_array)\n",
    "end_time = time.time()\n",
    "\n",
    "decoded_predictions = decode_predictions(predictions, top=5)[0]\n",
    "print('Predictions:')\n",
    "\n",
    "for i, (imagenet_id, label, score) in enumerate(decoded_predictions):\n",
    "    print(f'{i + 1}: {label} ({score:.2f})')\n",
    "\n",
    "top_class_index = np.argmax(predictions[0])\n",
    "print(f'\\nTop Prediction Class Index: {top_class_index}')\n",
    "\n",
    "inference_time_ms = (end_time - start_time) * 1000.0\n",
    "print(f\"Inference Time: {inference_time_ms:.2f} ms\")\n",
    "\n",
    "model_size_MB = model.count_params() * 4 / (1024 ** 2)\n",
    "print(f\"Size (MB): {model_size_MB:.2f} MB\")\n",
    "\n",
    "num_parameters = model.count_params()\n",
    "model_depth = len(model.layers)\n",
    "\n",
    "print(f\"Parameters: {num_parameters}\")\n",
    "print(f\"Depth: {model_depth}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60cafe0-1eb4-4d02-8bc1-75c7e6fbe093",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EfficientNetV2B0(weights='imagenet')\n",
    "img_path = r'E:\\PYTHONCLASSTF\\PrakashSenapati\\2024_11_25_Data_Augmentation_Kera_Packages\\dog_chihuahua.jpeg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = preprocess_input(img_array)\n",
    "\n",
    "start_time = time.time()\n",
    "predictions = model.predict(img_array)\n",
    "end_time = time.time()\n",
    "\n",
    "decoded_predictions = decode_predictions(predictions, top=5)[0]\n",
    "print('Predictions:')\n",
    "\n",
    "for i, (imagenet_id, label, score) in enumerate(decoded_predictions):\n",
    "    print(f'{i + 1}: {label} ({score:.2f})')\n",
    "\n",
    "top_class_index = np.argmax(predictions[0])\n",
    "print(f'\\nTop Prediction Class Index: {top_class_index}')\n",
    "\n",
    "inference_time_ms = (end_time - start_time) * 1000.0\n",
    "print(f\"Inference Time: {inference_time_ms:.2f} ms\")\n",
    "\n",
    "model_size_MB = model.count_params() * 4 / (1024 ** 2)\n",
    "print(f\"Size (MB): {model_size_MB:.2f} MB\")\n",
    "\n",
    "num_parameters = model.count_params()\n",
    "model_depth = len(model.layers)\n",
    "\n",
    "print(f\"Parameters: {num_parameters}\")\n",
    "print(f\"Depth: {model_depth}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflowkernel",
   "language": "python",
   "name": "tensorflowkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
